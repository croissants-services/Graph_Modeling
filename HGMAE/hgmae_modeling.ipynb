{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "031cdebc-bd5d-4f60-9d17-731230a39809",
   "metadata": {},
   "source": [
    "## Install Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762fe5b9-00cf-4363-8d0a-b9e3365da493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ac8b98-e11a-4e5c-a72b-d9f8a5b860c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.1.0+cu121\n",
      "Uninstalling torch-2.1.0+cu121:\n",
      "  Successfully uninstalled torch-2.1.0+cu121\n",
      "Found existing installation: torchvision 0.16.0+cu121\n",
      "Uninstalling torchvision-0.16.0+cu121:\n",
      "  Successfully uninstalled torchvision-0.16.0+cu121\n",
      "Found existing installation: torchaudio 2.1.0+cu121\n",
      "Uninstalling torchaudio-2.1.0+cu121:\n",
      "  Successfully uninstalled torchaudio-2.1.0+cu121\n",
      "Found existing installation: torchdata 0.7.0\n",
      "Uninstalling torchdata-0.7.0:\n",
      "  Successfully uninstalled torchdata-0.7.0\n",
      "Found existing installation: dgl 2.1.0+cu121\n",
      "Uninstalling dgl-2.1.0+cu121:\n",
      "  Successfully uninstalled dgl-2.1.0+cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio torchdata dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bbba00-477f-4609-b841-1fd160439a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: torchvision==0.16.0+cu121 in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
      "Requirement already satisfied: torchaudio==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0+cu121) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0+cu121) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.32.3)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata==0.7.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata==0.7.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
      "Collecting dgl\n",
      "  Using cached https://data.dgl.ai/wheels/cu121/dgl-2.1.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (467.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.8)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.7.4)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.5.0->dgl) (1.3.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-2.1.0+cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# PyTorch 2.1.0 + CUDA 12.1\n",
    "!pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# TorchData ÎßûÏ∂§\n",
    "!pip install torchdata==0.7.0\n",
    "\n",
    "# DGL with GraphBolt (CUDA 12.1)\n",
    "!pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9a593c-ca2d-4ba7-bd3c-f39ac60c2236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.0+cu121\n",
      "TorchData: 0.7.0\n",
      "Torchvision: 0.16.0+cu121\n",
      "Torchaudio: 2.1.0+cu121\n",
      "DGL: 2.1.0+cu121\n",
      "CUDA: 12.1\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "# ÏÑ§Ïπò ÌôïÏù∏ \n",
    "\n",
    "import torch, torchvision, torchaudio, torchdata, dgl\n",
    "import dgl.graphbolt as gb\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"TorchData:\", torchdata.__version__)\n",
    "print(\"Torchvision:\", torchvision.__version__)\n",
    "print(\"Torchaudio:\", torchaudio.__version__)\n",
    "print(\"DGL:\", dgl.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ad51ce-e18a-4001-86ba-ed14f3739763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (0.7.5)\n"
     ]
    }
   ],
   "source": [
    "# warning message ÎÅÑÍ∏∞\n",
    "!pip install pickleshare --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bbc6333-f3c2-457e-9367-bb608047f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdada895-05d6-450b-a481-d549b8619363",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af77f237-4f71-4451-bc32-dd0dfa123af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, torchaudio, torchdata, dgl\n",
    "import dgl.graphbolt as gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30c0d17-8306-4876-89d8-95273c97bba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01be5344-5b7e-427d-878c-eae55dde8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in mydata.pkl: dict_keys(['feats', 'mps', 'nei_index', 'pos'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"data/mydata.pkl\")\n",
    "\n",
    "import torch\n",
    "data = torch.load(\"data/mydata.pkl\")\n",
    "print(\"keys in mydata.pkl:\", data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d29ad86-b7a2-4957-a6dd-4df114a7f829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper torch.Size([5000, 832])\n",
      "author torch.Size([33607, 768])\n",
      "concept torch.Size([6612, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"data/mydata.pkl\")\n",
    "\n",
    "for k in data[\"feats\"]:\n",
    "    print(k, data[\"feats\"][k].shape)\n",
    "\n",
    "# paper torch.Size([5000, 832])\n",
    "# author torch.Size([33607, 768])\n",
    "# concept torch.Size([6612, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee0e2ae-27f1-4c20-8145-cf694761125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap torch.Size([2, 40758])\n",
      "pc torch.Size([2, 82238])\n",
      "pp torch.Size([2, 8186])\n",
      "aa torch.Size([2, 984700])\n"
     ]
    }
   ],
   "source": [
    "for name, edge_index in data[\"pos\"].items():\n",
    "    print(name, edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354a8361-569a-41c4-b6f9-a71003515460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAP torch.Size([33607, 33607])\n",
      "PCP torch.Size([5000, 5000])\n"
     ]
    }
   ],
   "source": [
    "for name, mat in data[\"mps\"].items():\n",
    "    print(name, mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addb7d09-9b87-4993-b632-ef5d5aeee2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python main.py --dataset mydata --task contrastive --use_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c4bd7b-8ed0-4fe9-a91b-fbc18fe9c5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n",
      "Namespace(seeds=[0], num_heads=4, num_out_heads=1, num_layers=2, residual=False, feat_drop=0.2, attn_drop=0.1, norm=None, lr=0.001, negative_slope=0.2, activation='prelu', feat_mask_rate='0.3,0.05,0.7', replace_rate=0.0, leave_unchanged=0.0, encoder='han', decoder='han', loss_fn='mse', alpha_l=2, optimizer='adam', scheduler=False, scheduler_gamma=0.99, dataset='mydata', ratio=[20, 40, 60], gpu=0, seed=0, hidden_dim=512, mae_epochs=50, eva_lr=0.05, eva_wd=0.0, patience=10, l2_coef=0.0005, use_mp2vec_feat_pred=False, mps_lr=0.005, mps_embedding_dim=64, mps_walk_length=5, mps_context_size=3, mps_walks_per_node=3, mps_num_negative_samples=1, mps_batch_size=128, mps_epoch=20, mp2vec_feat_pred_loss_weight=0.1, mp2vec_feat_alpha_l=2, mp2vec_feat_drop=0.2, use_cfg=False, use_mp_edge_recon=False, mp_edge_recon_loss_weight=1, mp_edge_mask_rate='0.5,0.005,0.8', mp_edge_alpha_l=2, task='contrastive', contrastive_weight=1.0, mae_weight=1.0, tau=0.5, hard_neg_weight=0.0, epochs=20, batch_size=128, type_num=[5000, 33607, 6612], nei_num=2, node_types=['paper', 'author', 'concept'], device=device(type='cpu'), val_ratio=0.15)\n",
      ">> Loading custom mydata.pkl (meta-paths: PAP, PCP) ...\n",
      "Raw ‚Üí Anchor mapping overview:\n",
      "  raw 'pp' ‚Üí anchor 'paper' | shape=(2, 8186)\n",
      "  raw 'aa' ‚Üí anchor 'author' | shape=(2, 984700)\n",
      "[POS] anchor=paper, edges shape=(8026, 2)\n",
      "[POS] anchor=author, edges shape=(984548, 2)\n",
      "[Check] Node feature shapes:\n",
      "  paper: (5000, 832)\n",
      "  author: (33607, 768)\n",
      "  concept: (6612, 768)\n",
      "Dataset: mydata\n",
      "Meta-paths: ['PAP', 'PCP']\n",
      "Feats rows (actual): [5000, 33607, 6612]\n",
      "Feature dims: [832, 768, 768]\n",
      "Negative sampling:   0%|                               | 0/2 [00:00<?, ?etype/s][INFO] paper: pos=8026, neg=8025\n",
      "[INFO] author: pos=984548, neg=984517\n",
      "Negative sampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 21.71etype/s]\n",
      "üíæ Saved pairs_debug.pkl\n",
      "[PAIR] author: pos_train=836,866, pos_val=147,682, neg_train=836,840, neg_val=147,677\n",
      "[PAIR] paper: pos_train=6,823, pos_val=1,203, neg_train=6,822, neg_val=1,203\n",
      "‚úÖ Training start...\n",
      "Epoch 000 | Train 90.6911 | Val 19.5128                                         \n",
      "Epoch 001 | Train 16.0902 | Val 5.0581                                          \n",
      "Epoch 002 | Train 4.1218 | Val 2.4031                                           \n",
      "Epoch 003 | Train 1.9897 | Val 1.5993                                           \n",
      "Epoch 004 | Train 1.3906 | Val 1.2533                                           \n",
      "Epoch 005 | Train 1.1569 | Val 1.1094                                           \n",
      "Epoch 006 | Train 1.0648 | Val 1.0488                                           \n",
      "Epoch 007 | Train 1.0278 | Val 1.0202                                           \n",
      "Epoch 008 | Train 1.0085 | Val 1.0060                                           \n",
      "Epoch 009 | Train 1.0058 | Val 1.0036                                           \n",
      "Epoch 010 | Train 1.0041 | Val 1.0025                                           \n",
      "Epoch 011 | Train 1.0029 | Val 1.0012                                           \n",
      "Epoch 012 | Train 1.0012 | Val 0.9997                                           \n",
      "Epoch 013 | Train 1.0006 | Val 0.9985                                           \n",
      "Epoch 014 | Train 0.9984 | Val 0.9966                                           \n",
      "Epoch 015 | Train 0.9968 | Val 0.9946                                           \n",
      "Epoch 016 | Train 0.9947 | Val 0.9933                                           \n",
      "Epoch 017 | Train 0.9932 | Val 0.9914                                           \n",
      "Epoch 018 | Train 0.9912 | Val 0.9900                                           \n",
      "Epoch 019 | Train 0.9898 | Val 0.9877                                           \n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [11:16<00:00, 33.81s/epoch]\n",
      "Best epoch: 19\n",
      "‚úÖ Best model saved: best_model.pt\n",
      "üìà Saved loss_curve.png\n",
      "‚úÖ Contrastive finished\n",
      "Embeddings: torch.Size([5000, 512])\n",
      "Saved: /root/HGMAE/embeddings.npy\n",
      "‚è±Ô∏è Total time: 683 s\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE\n",
    "!python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd4871-28da-47d4-b8f4-bba37c251dfd",
   "metadata": {},
   "source": [
    "### ÌïôÏäµ Ïûò ÎèåÏïÑÍ∞îÎäîÏßÄ ÌôïÏù∏ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921acb16-2858-46d0-9722-c29f04318e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n",
      "Top-level keys: dict_keys(['pos', 'neg'])\n",
      "Subkeys (pos): dict_keys(['train', 'val'])\n",
      "Subkeys (neg): dict_keys(['train', 'val'])\n",
      "\n",
      "=== POS_TRAIN[PAPER] ===\n",
      "Ï¥ù Í∞úÏàò: 6823\n",
      "Ï§ëÎ≥µ Ï†úÍ±∞ ÌõÑ Í∞úÏàò: 6823 (Ï§ëÎ≥µ 0)\n",
      "Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ ÎÖ∏Îìú index Í∞úÏàò: 0\n",
      "\n",
      "=== NEG_TRAIN[PAPER] ===\n",
      "Ï¥ù Í∞úÏàò: 6822\n",
      "Ï§ëÎ≥µ Ï†úÍ±∞ ÌõÑ Í∞úÏàò: 6822 (Ï§ëÎ≥µ 0)\n",
      "Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ ÎÖ∏Îìú index Í∞úÏàò: 0\n",
      "\n",
      "Pos-Neg ÍµêÏßëÌï© Í∞úÏàò: 0\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# ÌååÏùº Î°úÎìú\n",
    "with open(\"pairs_debug.pkl\", \"rb\") as f:\n",
    "    pairs = pickle.load(f)\n",
    "\n",
    "print(\"Top-level keys:\", pairs.keys())\n",
    "print(\"Subkeys (pos):\", pairs[\"pos\"].keys())\n",
    "print(\"Subkeys (neg):\", pairs[\"neg\"].keys())\n",
    "\n",
    "def check_edges(edges, name, num_nodes=None):\n",
    "    print(f\"\\n=== {name.upper()} ===\")\n",
    "    if edges is None or len(edges) == 0:\n",
    "        print(\"‚ö†Ô∏è ÏóÜÏùå\")\n",
    "        return None\n",
    "    \n",
    "    if isinstance(edges, torch.Tensor):\n",
    "        e = edges.clone().cpu()\n",
    "        if e.ndim == 2 and e.shape[0] == 2:\n",
    "            e = e.t()\n",
    "    else:\n",
    "        e = torch.as_tensor(edges, dtype=torch.long)\n",
    "        if e.ndim == 2 and e.shape[0] == 2:\n",
    "            e = e.t()\n",
    "    \n",
    "    print(f\"Ï¥ù Í∞úÏàò: {e.shape[0]}\")\n",
    "    \n",
    "    uniq = torch.unique(e, dim=0)\n",
    "    print(f\"Ï§ëÎ≥µ Ï†úÍ±∞ ÌõÑ Í∞úÏàò: {uniq.shape[0]} (Ï§ëÎ≥µ {e.shape[0] - uniq.shape[0]})\")\n",
    "    \n",
    "    if num_nodes:\n",
    "        invalid = ((e < 0) | (e >= num_nodes)).any(dim=1).sum().item()\n",
    "        print(f\"Ïú†Ìö®ÌïòÏßÄ ÏïäÏùÄ ÎÖ∏Îìú index Í∞úÏàò: {invalid}\")\n",
    "    \n",
    "    return e\n",
    "\n",
    "# ÏòàÏãú: paper ÌÉÄÏûÖÎßå ÌôïÏù∏\n",
    "pos_paper = pairs[\"pos\"][\"train\"].get(\"paper\")\n",
    "neg_paper = pairs[\"neg\"][\"train\"].get(\"paper\")\n",
    "\n",
    "pos_e = check_edges(pos_paper, \"pos_train[paper]\", num_nodes=5000)\n",
    "neg_e = check_edges(neg_paper, \"neg_train[paper]\", num_nodes=5000)\n",
    "\n",
    "# pos-neg ÍµêÏßëÌï©\n",
    "if pos_e is not None and neg_e is not None:\n",
    "    inter = set(map(tuple, pos_e.tolist())) & set(map(tuple, neg_e.tolist()))\n",
    "    print(f\"\\nPos-Neg ÍµêÏßëÌï© Í∞úÏàò: {len(inter)}\")\n",
    "    if len(inter) > 0:\n",
    "        print(\"ÏòàÏãú ÍµêÏßëÌï©:\", list(inter)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4c7a24-07d1-4caf-88ca-d8a88b4cc43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n",
      "Keys in mydata.pkl: dict_keys(['feats', 'mps', 'nei_index', 'pos'])\n",
      "Type of pos: <class 'dict'>\n",
      "ap: shape=torch.Size([2, 40758]) type=<class 'torch.Tensor'>\n",
      "pc: shape=torch.Size([2, 82238]) type=<class 'torch.Tensor'>\n",
      "pp: shape=torch.Size([2, 8186]) type=<class 'torch.Tensor'>\n",
      "aa: shape=torch.Size([2, 984700]) type=<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE\n",
    "import torch\n",
    "\n",
    "data = torch.load(\"data/mydata.pkl\", map_location=\"cpu\")  # GPU ‚Üí CPU Î°úÎìú\n",
    "print(\"Keys in mydata.pkl:\", data.keys())\n",
    "\n",
    "if \"pos\" in data:\n",
    "    pos = data[\"pos\"]\n",
    "    print(\"Type of pos:\", type(pos))\n",
    "    if isinstance(pos, dict):\n",
    "        for k, v in pos.items():\n",
    "            print(f\"{k}: shape={getattr(v, 'shape', None)} type={type(v)}\")\n",
    "    else:\n",
    "        print(\"pos content:\", pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02ce15-57fa-425c-8dcb-9fcf9d319278",
   "metadata": {},
   "source": [
    "## Tuning & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312edf9d-0c29-485c-af85-06355b5cfad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \\\"./main.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\",\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \\\"./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\"\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:    \\\"!grep -r \\\\\\\"for epoch in\\\\\\\" .\\\"\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./data/HGMAE_2ndtrial.ipynb:      \\\"./main.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\",\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./data/HGMAE_2ndtrial.ipynb:      \\\"./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\"\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./data/HGMAE_2ndtrial.ipynb:    \\\"!grep -r \\\\\\\"for epoch in\\\\\\\" .\\\"\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./main.py:    for epoch in tqdm(range(args.epochs), desc=\\\"Training\\\", unit=\\\"epoch\\\"):\\n\",\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \"./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.epochs), desc=\\\"Training\\\", unit=\\\"epoch\\\"):\\n\"\n",
      "./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:    \"!grep -r \\\"for epoch in\\\" .\"\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \\\"./main.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\",\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:      \\\"./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\"\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./data/.ipynb_checkpoints/HGMAE_2ndtrial-checkpoint.ipynb:    \\\"!grep -r \\\\\\\"for epoch in\\\\\\\" .\\\"\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./data/HGMAE_2ndtrial.ipynb:      \\\"./main.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\",\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./data/HGMAE_2ndtrial.ipynb:      \\\"./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.mae_epochs), desc=\\\\\\\"Training\\\\\\\", unit=\\\\\\\"epoch\\\\\\\"):\\\\n\\\"\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./data/HGMAE_2ndtrial.ipynb:    \\\"!grep -r \\\\\\\"for epoch in\\\\\\\" .\\\"\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./main.py:    for epoch in tqdm(range(args.epochs), desc=\\\"Training\\\", unit=\\\"epoch\\\"):\\n\",\n",
      "./data/HGMAE_2ndtrial.ipynb:      \"./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.epochs), desc=\\\"Training\\\", unit=\\\"epoch\\\"):\\n\"\n",
      "./data/HGMAE_2ndtrial.ipynb:    \"!grep -r \\\"for epoch in\\\" .\"\n",
      "./main.py:    for epoch in tqdm(range(args.epochs), desc=\"Training\", unit=\"epoch\"):\n",
      "./.ipynb_checkpoints/main-checkpoint.py:    for epoch in tqdm(range(args.epochs), desc=\"Training\", unit=\"epoch\"):\n"
     ]
    }
   ],
   "source": [
    "!grep -r \"for epoch in\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f070261a-e463-4e7f-80bc-bfef50af5b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(seeds=[0], num_heads=4, num_out_heads=1, num_layers=2, residual=False, feat_drop=0.2, attn_drop=0.1, norm=None, lr=0.001, negative_slope=0.2, activation='prelu', feat_mask_rate='0.3,0.05,0.7', replace_rate=0.0, leave_unchanged=0.0, encoder='han', decoder='han', loss_fn='mse', alpha_l=2, optimizer='adam', scheduler=False, scheduler_gamma=0.99, dataset='mydata', ratio=[20, 40, 60], gpu=0, seed=0, hidden_dim=512, mae_epochs=50, eva_lr=0.05, eva_wd=0.0, patience=10, l2_coef=0.0005, use_mp2vec_feat_pred=False, mps_lr=0.005, mps_embedding_dim=64, mps_walk_length=5, mps_context_size=3, mps_walks_per_node=3, mps_num_negative_samples=1, mps_batch_size=128, mps_epoch=20, mp2vec_feat_pred_loss_weight=0.1, mp2vec_feat_alpha_l=2, mp2vec_feat_drop=0.2, use_cfg=False, use_mp_edge_recon=False, mp_edge_recon_loss_weight=1, mp_edge_mask_rate='0.5,0.005,0.8', mp_edge_alpha_l=2, task='contrastive', contrastive_weight=1.0, mae_weight=1.0, tau=0.5, hard_neg_weight=0.0, epochs=80, batch_size=128, type_num=[5000, 33607, 6612], nei_num=2, node_types=['paper', 'author', 'concept'], device=device(type='cpu'), val_ratio=0.15)\n",
      ">> Loading custom mydata.pkl (meta-paths: PAP, PCP) ...\n",
      "Raw ‚Üí Anchor mapping overview:\n",
      "  raw 'pp' ‚Üí anchor 'paper' | shape=(2, 8186)\n",
      "  raw 'aa' ‚Üí anchor 'author' | shape=(2, 984700)\n",
      "[POS] anchor=paper, edges shape=(8026, 2)\n",
      "[POS] anchor=author, edges shape=(984548, 2)\n",
      "[Check] Node feature shapes:\n",
      "  paper: (5000, 832)\n",
      "  author: (33607, 768)\n",
      "  concept: (6612, 768)\n",
      "Dataset: mydata\n",
      "Meta-paths: ['PAP', 'PCP']\n",
      "Feats rows (actual): [5000, 33607, 6612]\n",
      "Feature dims: [832, 768, 768]\n",
      "Negative sampling:   0%|                               | 0/2 [00:00<?, ?etype/s][INFO] paper: pos=8026, neg=8025\n",
      "[INFO] author: pos=984548, neg=984517\n",
      "Negative sampling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 23.46etype/s]\n",
      "üíæ Saved pairs_debug.pkl\n",
      "[PAIR] author: pos_train=836,866, pos_val=147,682, neg_train=836,840, neg_val=147,677\n",
      "[PAIR] paper: pos_train=6,823, pos_val=1,203, neg_train=6,822, neg_val=1,203\n",
      "‚úÖ Training start...\n",
      "Epoch 000 | Train 90.6911 | Val 19.5128                                         \n",
      "Epoch 001 | Train 16.0902 | Val 5.0581                                          \n",
      "Epoch 002 | Train 4.1218 | Val 2.4031                                           \n",
      "Epoch 003 | Train 1.9897 | Val 1.5993                                           \n",
      "Epoch 004 | Train 1.3906 | Val 1.2533                                           \n",
      "Epoch 005 | Train 1.1569 | Val 1.1094                                           \n",
      "Epoch 006 | Train 1.0648 | Val 1.0488                                           \n",
      "Epoch 007 | Train 1.0278 | Val 1.0202                                           \n",
      "Epoch 008 | Train 1.0085 | Val 1.0060                                           \n",
      "Epoch 009 | Train 1.0058 | Val 1.0036                                           \n",
      "Epoch 010 | Train 1.0041 | Val 1.0025                                           \n",
      "Epoch 011 | Train 1.0029 | Val 1.0012                                           \n",
      "Epoch 012 | Train 1.0012 | Val 0.9997                                           \n",
      "Epoch 013 | Train 1.0006 | Val 0.9985                                           \n",
      "Epoch 014 | Train 0.9984 | Val 0.9966                                           \n",
      "Epoch 015 | Train 0.9968 | Val 0.9946                                           \n",
      "Epoch 016 | Train 0.9947 | Val 0.9933                                           \n",
      "Epoch 017 | Train 0.9932 | Val 0.9914                                           \n",
      "Epoch 018 | Train 0.9912 | Val 0.9900                                           \n",
      "Epoch 019 | Train 0.9898 | Val 0.9877                                           \n",
      "Epoch 020 | Train 0.9886 | Val 0.9865                                           \n",
      "Epoch 021 | Train 0.9874 | Val 0.9855                                           \n",
      "Epoch 022 | Train 0.9851 | Val 0.9837                                           \n",
      "Epoch 023 | Train 0.9840 | Val 0.9821                                           \n",
      "Epoch 024 | Train 0.9826 | Val 0.9809                                           \n",
      "Epoch 025 | Train 0.9810 | Val 0.9795                                           \n",
      "Epoch 026 | Train 0.9795 | Val 0.9783                                           \n",
      "Epoch 027 | Train 0.9783 | Val 0.9770                                           \n",
      "Epoch 028 | Train 0.9773 | Val 0.9754                                           \n",
      "Epoch 029 | Train 0.9760 | Val 0.9745                                           \n",
      "Epoch 030 | Train 0.9747 | Val 0.9734                                           \n",
      "Epoch 031 | Train 0.9735 | Val 0.9721                                           \n",
      "Epoch 032 | Train 0.9724 | Val 0.9710                                           \n",
      "Epoch 033 | Train 0.9712 | Val 0.9701                                           \n",
      "Epoch 034 | Train 0.9696 | Val 0.9683                                           \n",
      "Epoch 035 | Train 0.9687 | Val 0.9672                                           \n",
      "Epoch 036 | Train 0.9672 | Val 0.9660                                           \n",
      "Epoch 037 | Train 0.9662 | Val 0.9650                                           \n",
      "Epoch 038 | Train 0.9651 | Val 0.9632                                           \n",
      "Epoch 039 | Train 0.9633 | Val 0.9623                                           \n",
      "Epoch 040 | Train 0.9621 | Val 0.9606                                           \n",
      "Epoch 041 | Train 0.9607 | Val 0.9594                                           \n",
      "Epoch 042 | Train 0.9600 | Val 0.9576                                           \n",
      "Epoch 043 | Train 0.9573 | Val 0.9562                                           \n",
      "Epoch 044 | Train 0.9559 | Val 0.9541                                           \n",
      "Epoch 045 | Train 0.9538 | Val 0.9505                                           \n",
      "Epoch 046 | Train 0.9501 | Val 0.9455                                           \n",
      "Epoch 047 | Train 0.9450 | Val 0.9385                                           \n",
      "Epoch 048 | Train 0.9383 | Val 0.9294                                           \n",
      "Epoch 049 | Train 0.9289 | Val 0.9170                                           \n",
      "Epoch 050 | Train 0.9169 | Val 0.9023                                           \n",
      "Epoch 051 | Train 0.9021 | Val 0.8879                                           \n",
      "Epoch 052 | Train 0.8876 | Val 0.8762                                           \n",
      "Epoch 053 | Train 0.8755 | Val 0.8673                                           \n",
      "Epoch 054 | Train 0.8660 | Val 0.8606                                           \n",
      "Epoch 055 | Train 0.8601 | Val 0.8561                                           \n",
      "Epoch 056 | Train 0.8562 | Val 0.8536                                           \n",
      "Epoch 057 | Train 0.8536 | Val 0.8509                                           \n",
      "Epoch 058 | Train 0.8520 | Val 0.8474                                           \n",
      "Epoch 059 | Train 0.8480 | Val 0.8432                                           \n",
      "Epoch 060 | Train 0.8440 | Val 0.8361                                           \n",
      "Epoch 061 | Train 0.8373 | Val 0.8300                                           \n",
      "Epoch 062 | Train 0.8302 | Val 0.8233                                           \n",
      "Epoch 063 | Train 0.8234 | Val 0.8182                                           \n",
      "Epoch 064 | Train 0.8179 | Val 0.8146                                           \n",
      "Epoch 065 | Train 0.8143 | Val 0.8120                                           \n",
      "Epoch 066 | Train 0.8118 | Val 0.8112                                           \n",
      "Epoch 067 | Train 0.8104 | Val 0.8111                                           \n",
      "Epoch 068 | Train 0.8101 | Val 0.8106                                           \n",
      "Epoch 069 | Train 0.8103 | Val 0.8103                                           \n",
      "Epoch 070 | Train 0.8097 | Val 0.8087                                           \n",
      "Epoch 071 | Train 0.8081 | Val 0.8062                                           \n",
      "Epoch 072 | Train 0.8060 | Val 0.8038                                           \n",
      "Epoch 073 | Train 0.8039 | Val 0.8014                                           \n",
      "Epoch 074 | Train 0.8018 | Val 0.7997                                           \n",
      "Epoch 075 | Train 0.7994 | Val 0.7992                                           \n",
      "Epoch 076 | Train 0.7992 | Val 0.7982                                           \n",
      "Epoch 077 | Train 0.7989 | Val 0.7975                                           \n",
      "Epoch 078 | Train 0.7971 | Val 0.7966                                           \n",
      "Epoch 079 | Train 0.7972 | Val 0.7961                                           \n",
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [52:04<00:00, 39.06s/epoch]\n",
      "Best epoch: 79\n",
      "‚úÖ Best model saved: best_model.pt\n",
      "üìà Saved loss_curve.png\n",
      "‚úÖ Contrastive finished\n",
      "Embeddings: torch.Size([5000, 512])\n",
      "Saved: /root/HGMAE/embeddings.npy\n",
      "‚è±Ô∏è Total time: 3133 s\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d709a7-4fe4-4b51-a50c-6df6e15cf5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def sweep_hyperparams(lr_list, epoch_list, dataset=\"mydata\", task=\"contrastive\", seeds=[0]):\n",
    "    \"\"\"\n",
    "    main.py Ïó¨Îü¨ Î≤à Ïã§Ìñâ ‚Üí stdoutÏóêÏÑú losfs Í∞í Ï∂îÏ∂ú ‚Üí Ìëú(DataFrame) Î∞òÌôò\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for lr, ep, seed in itertools.product(lr_list, epoch_list, seeds):\n",
    "        tag = f\"lr{lr}_ep{ep}_s{seed}\"\n",
    "        save_dir = os.path.join(\"runs\", tag)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        cmd = [\n",
    "            \"python\", \"main.py\",\n",
    "            \"--task\", task,\n",
    "            \"--dataset\", dataset,\n",
    "            \"--lr\", str(lr),\n",
    "            \"--epochs\", str(ep),\n",
    "            \"--seed\", str(seed),\n",
    "            \"--save_dir\", save_dir,\n",
    "            \"--exp_name\", tag\n",
    "        ]\n",
    "        print(\">> Ïã§Ìñâ:\", \" \".join(cmd))\n",
    "\n",
    "        # stdout Ï∫°Ï≤ò\n",
    "        proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "        # stdout ÎùºÏù∏Î≥Ñ Î∂ÑÎ¶¨\n",
    "        stdout_lines = proc.stdout.strip().split(\"\\n\")\n",
    "\n",
    "        # \"loss\" ÌÇ§ÏõåÎìúÍ∞Ä Ìè¨Ìï®Îêú Ï§Ñ Ï∞æÍ∏∞\n",
    "        loss_lines = [line for line in stdout_lines if \"loss\" in line.lower()]\n",
    "        if loss_lines:\n",
    "            final_loss_line = loss_lines[-1]  # ÎßàÏßÄÎßâ loss Ï§Ñ\n",
    "        else:\n",
    "            final_loss_line = \"Not found\"\n",
    "\n",
    "        # Í≤∞Í≥º Ï†ÄÏû•\n",
    "        results.append({\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": ep,\n",
    "            \"seed\": seed,\n",
    "            \"save_dir\": save_dir,\n",
    "            \"final_loss\": final_loss_line\n",
    "        })\n",
    "\n",
    "    # DataFrameÏúºÎ°ú Ï†ïÎ¶¨\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0dceef2-1f01-4d96-b01b-d852bb25efbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 25 --seed 0 --save_dir runs/lr0.001_ep25_s0 --exp_name lr0.001_ep25_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 25 --seed 1 --save_dir runs/lr0.001_ep25_s1 --exp_name lr0.001_ep25_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 50 --seed 0 --save_dir runs/lr0.001_ep50_s0 --exp_name lr0.001_ep50_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 50 --seed 1 --save_dir runs/lr0.001_ep50_s1 --exp_name lr0.001_ep50_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 25 --seed 0 --save_dir runs/lr0.0005_ep25_s0 --exp_name lr0.0005_ep25_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 25 --seed 1 --save_dir runs/lr0.0005_ep25_s1 --exp_name lr0.0005_ep25_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 50 --seed 0 --save_dir runs/lr0.0005_ep50_s0 --exp_name lr0.0005_ep50_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 50 --seed 1 --save_dir runs/lr0.0005_ep50_s1 --exp_name lr0.0005_ep50_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0001 --epochs 25 --seed 0 --save_dir runs/lr0.0001_ep25_s0 --exp_name lr0.0001_ep25_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0001 --epochs 25 --seed 1 --save_dir runs/lr0.0001_ep25_s1 --exp_name lr0.0001_ep25_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0001 --epochs 50 --seed 0 --save_dir runs/lr0.0001_ep50_s0 --exp_name lr0.0001_ep50_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0001 --epochs 50 --seed 1 --save_dir runs/lr0.0001_ep50_s1 --exp_name lr0.0001_ep50_s1\n",
      "        lr  epochs  seed               save_dir  \\\n",
      "0   0.0010      25     0   runs/lr0.001_ep25_s0   \n",
      "1   0.0010      25     1   runs/lr0.001_ep25_s1   \n",
      "2   0.0010      50     0   runs/lr0.001_ep50_s0   \n",
      "3   0.0010      50     1   runs/lr0.001_ep50_s1   \n",
      "4   0.0005      25     0  runs/lr0.0005_ep25_s0   \n",
      "5   0.0005      25     1  runs/lr0.0005_ep25_s1   \n",
      "6   0.0005      50     0  runs/lr0.0005_ep50_s0   \n",
      "7   0.0005      50     1  runs/lr0.0005_ep50_s1   \n",
      "8   0.0001      25     0  runs/lr0.0001_ep25_s0   \n",
      "9   0.0001      25     1  runs/lr0.0001_ep25_s1   \n",
      "10  0.0001      50     0  runs/lr0.0001_ep50_s0   \n",
      "11  0.0001      50     1  runs/lr0.0001_ep50_s1   \n",
      "\n",
      "                            final_loss  \n",
      "0   Saved loss curve to loss_curve.png  \n",
      "1   Saved loss curve to loss_curve.png  \n",
      "2   Saved loss curve to loss_curve.png  \n",
      "3   Saved loss curve to loss_curve.png  \n",
      "4   Saved loss curve to loss_curve.png  \n",
      "5   Saved loss curve to loss_curve.png  \n",
      "6   Saved loss curve to loss_curve.png  \n",
      "7   Saved loss curve to loss_curve.png  \n",
      "8   Saved loss curve to loss_curve.png  \n",
      "9   Saved loss curve to loss_curve.png  \n",
      "10  Saved loss curve to loss_curve.png  \n",
      "11  Saved loss curve to loss_curve.png  \n"
     ]
    }
   ],
   "source": [
    "lr_list = [1e-3, 5e-4, 1e-4]\n",
    "epoch_list = [25,50]\n",
    "\n",
    "df_results = sweep_hyperparams(lr_list, epoch_list, seeds=[0, 1])\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deed956-94df-4fdc-9350-f33153094fc0",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ab2842-2c4c-4f1b-ab09-ae7815a78d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/root/HGMAE/data/main.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "321a32e8-b943-4d5f-be3f-20ee5ecfd6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 50 --seed 0 --save_dir runs/lr0.001_ep50_s0 --exp_name lr0.001_ep50_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.001 --epochs 50 --seed 1 --save_dir runs/lr0.001_ep50_s1 --exp_name lr0.001_ep50_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 50 --seed 0 --save_dir runs/lr0.0005_ep50_s0 --exp_name lr0.0005_ep50_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0005 --epochs 50 --seed 1 --save_dir runs/lr0.0005_ep50_s1 --exp_name lr0.0005_ep50_s1\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0001 --epochs 50 --seed 0 --save_dir runs/lr0.0001_ep50_s0 --exp_name lr0.0001_ep50_s0\n",
      ">> Ïã§Ìñâ: python main.py --task contrastive --dataset mydata --lr 0.0001 --epochs 50 --seed 1 --save_dir runs/lr0.0001_ep50_s1 --exp_name lr0.0001_ep50_s1\n",
      "       lr  epochs  seed               save_dir  \\\n",
      "0  0.0010      50     0   runs/lr0.001_ep50_s0   \n",
      "1  0.0010      50     1   runs/lr0.001_ep50_s1   \n",
      "2  0.0005      50     0  runs/lr0.0005_ep50_s0   \n",
      "3  0.0005      50     1  runs/lr0.0005_ep50_s1   \n",
      "4  0.0001      50     0  runs/lr0.0001_ep50_s0   \n",
      "5  0.0001      50     1  runs/lr0.0001_ep50_s1   \n",
      "\n",
      "                                        final_loss  \n",
      "0  Epoch 023 | Train Loss 0.2406 | Val Loss 0.2379  \n",
      "1  Epoch 049 | Train Loss 0.2414 | Val Loss 0.2463  \n",
      "2  Epoch 023 | Train Loss 0.2406 | Val Loss 0.2379  \n",
      "3  Epoch 049 | Train Loss 0.2414 | Val Loss 0.2463  \n",
      "4  Epoch 023 | Train Loss 0.2406 | Val Loss 0.2379  \n",
      "5  Epoch 049 | Train Loss 0.2414 | Val Loss 0.2463  \n"
     ]
    }
   ],
   "source": [
    "lr_list = [1e-3, 5e-4, 1e-4]\n",
    "epoch_list = [50]\n",
    "\n",
    "df_results = sweep_hyperparams(lr_list, epoch_list, seeds=[0, 1])\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e500116-5f0b-432f-b6bd-dba5ba411214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf2ec3-9f1a-4d8d-b057-0f14ac94272d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
