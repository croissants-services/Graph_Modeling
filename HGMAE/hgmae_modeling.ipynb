{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fc40d6-79c1-4dcb-b6df-232d3ad5ac17",
   "metadata": {},
   "source": [
    "# HGMAE \n",
    "\n",
    "1. install module\n",
    "2. model training\n",
    "3. final embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031cdebc-bd5d-4f60-9d17-731230a39809",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Install Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762fe5b9-00cf-4363-8d0a-b9e3365da493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ac8b98-e11a-4e5c-a72b-d9f8a5b860c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.1.0+cu121\n",
      "Uninstalling torch-2.1.0+cu121:\n",
      "  Successfully uninstalled torch-2.1.0+cu121\n",
      "Found existing installation: torchvision 0.16.0+cu121\n",
      "Uninstalling torchvision-0.16.0+cu121:\n",
      "  Successfully uninstalled torchvision-0.16.0+cu121\n",
      "Found existing installation: torchaudio 2.1.0+cu121\n",
      "Uninstalling torchaudio-2.1.0+cu121:\n",
      "  Successfully uninstalled torchaudio-2.1.0+cu121\n",
      "Found existing installation: torchdata 0.7.0\n",
      "Uninstalling torchdata-0.7.0:\n",
      "  Successfully uninstalled torchdata-0.7.0\n",
      "Found existing installation: dgl 2.1.0+cu121\n",
      "Uninstalling dgl-2.1.0+cu121:\n",
      "  Successfully uninstalled dgl-2.1.0+cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio torchdata dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bbba00-477f-4609-b841-1fd160439a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: torchvision==0.16.0+cu121 in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
      "Requirement already satisfied: torchaudio==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0+cu121) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0+cu121) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.32.3)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata==0.7.0) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata==0.7.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata==0.7.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
      "Collecting dgl\n",
      "  Using cached https://data.dgl.ai/wheels/cu121/dgl-2.1.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (467.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.8)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.7.4)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2024.2.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.5.0->dgl) (1.3.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-2.1.0+cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# PyTorch 2.1.0 + CUDA 12.1\n",
    "!pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# TorchData 맞춤\n",
    "!pip install torchdata==0.7.0\n",
    "\n",
    "# DGL with GraphBolt (CUDA 12.1)\n",
    "!pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9a593c-ca2d-4ba7-bd3c-f39ac60c2236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.0+cu121\n",
      "TorchData: 0.7.0\n",
      "Torchvision: 0.16.0+cu121\n",
      "Torchaudio: 2.1.0+cu121\n",
      "DGL: 2.1.0+cu121\n",
      "CUDA: 12.1\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "# 설치 확인 \n",
    "\n",
    "import torch, torchvision, torchaudio, torchdata, dgl\n",
    "import dgl.graphbolt as gb\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"TorchData:\", torchdata.__version__)\n",
    "print(\"Torchvision:\", torchvision.__version__)\n",
    "print(\"Torchaudio:\", torchaudio.__version__)\n",
    "print(\"DGL:\", dgl.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ad51ce-e18a-4001-86ba-ed14f3739763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (0.7.5)\n"
     ]
    }
   ],
   "source": [
    "# warning message 끄기\n",
    "!pip install pickleshare --root-user-action=ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bbc6333-f3c2-457e-9367-bb608047f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdada895-05d6-450b-a481-d549b8619363",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af77f237-4f71-4451-bc32-dd0dfa123af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, torchaudio, torchdata, dgl\n",
    "import dgl.graphbolt as gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30c0d17-8306-4876-89d8-95273c97bba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01be5344-5b7e-427d-878c-eae55dde8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in mydata.pkl: dict_keys(['feats', 'mps', 'nei_index', 'pos'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"data/mydata.pkl\")\n",
    "\n",
    "import torch\n",
    "data = torch.load(\"data/mydata.pkl\")\n",
    "print(\"keys in mydata.pkl:\", data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d29ad86-b7a2-4957-a6dd-4df114a7f829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper torch.Size([5000, 832])\n",
      "author torch.Size([33607, 768])\n",
      "concept torch.Size([6612, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"data/mydata.pkl\")\n",
    "\n",
    "for k in data[\"feats\"]:\n",
    "    print(k, data[\"feats\"][k].shape)\n",
    "\n",
    "# paper torch.Size([5000, 832])\n",
    "# author torch.Size([33607, 768])\n",
    "# concept torch.Size([6612, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee0e2ae-27f1-4c20-8145-cf694761125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap torch.Size([2, 40758])\n",
      "pc torch.Size([2, 82238])\n",
      "pp torch.Size([2, 8186])\n",
      "aa torch.Size([2, 984700])\n"
     ]
    }
   ],
   "source": [
    "for name, edge_index in data[\"pos\"].items():\n",
    "    print(name, edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354a8361-569a-41c4-b6f9-a71003515460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAP torch.Size([33607, 33607])\n",
      "PCP torch.Size([5000, 5000])\n"
     ]
    }
   ],
   "source": [
    "for name, mat in data[\"mps\"].items():\n",
    "    print(name, mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addb7d09-9b87-4993-b632-ef5d5aeee2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n",
      "------ Use best configs ------\n",
      "Namespace(seeds=[0], num_heads=4, num_out_heads=1, num_layers=1, residual=True, feat_drop=0.2, attn_drop=0.2, norm='layernorm', lr=0.001, negative_slope=0.2, activation='prelu', feat_mask_rate='0.3,0.05,0.25', replace_rate=0.1, leave_unchanged=0.1, encoder='han', decoder='han', loss_fn='sce', alpha_l=2, optimizer='adam', scheduler='cosine', scheduler_gamma=0.99, dataset='mydata', ratio=[20, 40, 60], gpu=0, seed=0, hidden_dim=512, mae_epochs=50, eva_lr=0.05, eva_wd=0.0, patience=10, l2_coef=0.0005, use_mp2vec_feat_pred=False, mps_lr=0.005, mps_embedding_dim=64, mps_walk_length=5, mps_context_size=3, mps_walks_per_node=3, mps_num_negative_samples=1, mps_batch_size=128, mps_epoch=50, mp2vec_feat_pred_loss_weight=0.1, mp2vec_feat_alpha_l=2, mp2vec_feat_drop=0.2, use_cfg=True, use_mp_edge_recon=False, mp_edge_recon_loss_weight=1, mp_edge_mask_rate=0.3, mp_edge_alpha_l=2, task='contrastive', contrastive_weight=1.0, mae_weight=1.0, tau=0.5, hard_neg_weight=0.0, epochs=150, batch_size=128, type_num=[5000, 33607, 6612], nei_num=2, node_types=['paper', 'author', 'concept'], device=device(type='cpu'), mask_rate=0.3, n_labels=0, temperature=0.5, contrastive_loss_weight=1.0, recon_loss_weight=1.0, variance_loss_weight=0.001, val_ratio=0.15)\n",
      ">> Loading custom mydata.pkl (meta-paths: PAP, PCP) ...\n",
      "Raw → Anchor mapping overview:\n",
      "  raw 'pp' → anchor 'paper' | shape=(2, 8186)\n",
      "  raw 'aa' → anchor 'author' | shape=(2, 984700)\n",
      "[POS] anchor=paper, edges shape=(8026, 2)\n",
      "[POS] anchor=author, edges shape=(984548, 2)\n",
      "[Check] Node feature shapes:\n",
      "  paper: (5000, 832)\n",
      "  author: (33607, 768)\n",
      "  concept: (6612, 768)\n",
      "Dataset: mydata\n",
      "Meta-paths: ['PAP', 'PCP']\n",
      "Feats rows (actual): [5000, 33607, 6612]\n",
      "Feature dims: [832, 768, 768]\n",
      "Negative sampling:   0%|                               | 0/2 [00:00<?, ?etype/s][INFO] paper: pos=8026, neg=8025\n",
      "[INFO] author: pos=984548, neg=984517\n",
      "Negative sampling: 100%|███████████████████████| 2/2 [00:00<00:00, 43.48etype/s]\n",
      "💾 Saved pairs_debug.pkl\n",
      "[PAIR] author: pos_train=836,866, pos_val=147,682, neg_train=836,840, neg_val=147,677\n",
      "[PAIR] paper: pos_train=6,823, pos_val=1,203, neg_train=6,822, neg_val=1,203\n",
      "✅ Training start...\n",
      "Epoch 000 | Train 189.6978 | Val 135.8064                                       \n",
      "Epoch 001 | Train 126.1198 | Val 102.3009                                       \n",
      "Epoch 002 | Train 97.4278 | Val 93.9582                                         \n",
      "Epoch 003 | Train 89.1047 | Val 90.0653                                         \n",
      "Epoch 004 | Train 87.6348 | Val 86.5975                                         \n",
      "Epoch 005 | Train 85.7943 | Val 83.1390                                         \n",
      "Epoch 006 | Train 81.4720 | Val 78.3169                                         \n",
      "Epoch 007 | Train 75.9686 | Val 75.0500                                         \n",
      "Epoch 008 | Train 73.5808 | Val 71.4010                                         \n",
      "Epoch 009 | Train 71.9404 | Val 70.1478                                         \n",
      "Epoch 010 | Train 68.0375 | Val 68.0525                                         \n",
      "Epoch 011 | Train 67.4001 | Val 66.2610                                         \n",
      "Epoch 012 | Train 67.0536 | Val 63.4040                                         \n",
      "Epoch 013 | Train 64.1581 | Val 61.8670                                         \n",
      "Epoch 014 | Train 62.8324 | Val 61.1073                                         \n",
      "Epoch 015 | Train 60.0227 | Val 59.1888                                         \n",
      "Epoch 016 | Train 59.3217 | Val 56.1730                                         \n",
      "Epoch 017 | Train 57.7488 | Val 54.6833                                         \n",
      "Epoch 018 | Train 56.0553 | Val 54.3401                                         \n",
      "Epoch 019 | Train 54.9484 | Val 53.0048                                         \n",
      "Epoch 020 | Train 53.4797 | Val 51.8572                                         \n",
      "Epoch 021 | Train 52.7533 | Val 51.0792                                         \n",
      "Epoch 022 | Train 51.5739 | Val 50.6428                                         \n",
      "Epoch 023 | Train 50.8301 | Val 49.0916                                         \n",
      "Epoch 024 | Train 49.6928 | Val 49.2378                                         \n",
      "Epoch 025 | Train 48.2652 | Val 46.5975                                         \n",
      "Epoch 026 | Train 47.3734 | Val 45.8862                                         \n",
      "Epoch 027 | Train 46.4916 | Val 44.6717                                         \n",
      "Epoch 028 | Train 46.0580 | Val 43.7834                                         \n",
      "Epoch 029 | Train 44.7227 | Val 43.3840                                         \n",
      "Epoch 030 | Train 43.7030 | Val 42.8707                                         \n",
      "Epoch 031 | Train 43.5975 | Val 41.1627                                         \n",
      "Epoch 032 | Train 42.7357 | Val 41.2201                                         \n",
      "Epoch 033 | Train 41.4397 | Val 39.0788                                         \n",
      "Epoch 034 | Train 41.1371 | Val 38.8277                                         \n",
      "Epoch 035 | Train 39.8348 | Val 37.9114                                         \n",
      "Epoch 036 | Train 39.9829 | Val 38.1956                                         \n",
      "Epoch 037 | Train 39.5771 | Val 38.0510                                         \n",
      "Epoch 038 | Train 38.1478 | Val 37.2502                                         \n",
      "Epoch 039 | Train 38.2663 | Val 37.3875                                         \n",
      "Epoch 040 | Train 37.4221 | Val 36.1981                                         \n",
      "Epoch 041 | Train 37.6036 | Val 36.0630                                         \n",
      "Epoch 042 | Train 36.5488 | Val 35.2010                                         \n",
      "Epoch 043 | Train 35.7168 | Val 34.7483                                         \n",
      "Epoch 044 | Train 35.5154 | Val 34.0871                                         \n",
      "Epoch 045 | Train 34.5788 | Val 34.5808                                         \n",
      "Epoch 046 | Train 34.7553 | Val 32.8626                                         \n",
      "Epoch 047 | Train 33.8070 | Val 33.0625                                         \n",
      "Epoch 048 | Train 34.0655 | Val 31.7267                                         \n",
      "Epoch 049 | Train 32.7087 | Val 31.4240                                         \n",
      "Epoch 050 | Train 33.2912 | Val 31.5324                                         \n",
      "Epoch 051 | Train 32.3060 | Val 30.9302                                         \n",
      "Epoch 052 | Train 32.2762 | Val 31.7832                                         \n",
      "Epoch 053 | Train 32.0286 | Val 31.6412                                         \n",
      "Epoch 054 | Train 31.3442 | Val 31.5226                                         \n",
      "Epoch 055 | Train 31.3843 | Val 30.3648                                         \n",
      "Epoch 056 | Train 30.5926 | Val 29.5613                                         \n",
      "Epoch 057 | Train 30.8804 | Val 29.0066                                         \n",
      "Epoch 058 | Train 30.5942 | Val 29.4332                                         \n",
      "Epoch 059 | Train 29.7808 | Val 27.5023                                         \n",
      "Epoch 060 | Train 29.8827 | Val 27.7977                                         \n",
      "Epoch 061 | Train 29.3750 | Val 28.6950                                         \n",
      "Epoch 062 | Train 28.4977 | Val 28.6478                                         \n",
      "Epoch 063 | Train 28.8098 | Val 27.2683                                         \n",
      "Epoch 064 | Train 28.3250 | Val 27.6024                                         \n",
      "Epoch 065 | Train 27.4697 | Val 26.8334                                         \n",
      "Epoch 066 | Train 27.4574 | Val 26.8570                                         \n",
      "Epoch 067 | Train 27.7084 | Val 27.0957                                         \n",
      "Epoch 068 | Train 27.6167 | Val 26.2048                                         \n",
      "Epoch 069 | Train 27.5441 | Val 26.1415                                         \n",
      "Epoch 070 | Train 26.6456 | Val 26.3864                                         \n",
      "Epoch 071 | Train 26.3852 | Val 26.2648                                         \n",
      "Epoch 072 | Train 26.4852 | Val 24.9146                                         \n",
      "Epoch 073 | Train 26.1207 | Val 25.8150                                         \n",
      "Epoch 074 | Train 25.6038 | Val 24.2493                                         \n",
      "Epoch 075 | Train 25.8052 | Val 24.3289                                         \n",
      "Epoch 076 | Train 25.1337 | Val 25.4290                                         \n",
      "Epoch 077 | Train 25.0083 | Val 24.0266                                         \n",
      "Epoch 078 | Train 25.1068 | Val 24.5928                                         \n",
      "Epoch 079 | Train 24.7002 | Val 23.6165                                         \n",
      "Epoch 080 | Train 24.5658 | Val 23.6378                                         \n",
      "Epoch 081 | Train 24.2417 | Val 24.4550                                         \n",
      "Epoch 082 | Train 23.9217 | Val 22.6831                                         \n",
      "Epoch 083 | Train 23.5306 | Val 23.1896                                         \n",
      "Epoch 084 | Train 24.2315 | Val 21.3295                                         \n",
      "Epoch 085 | Train 23.2040 | Val 22.8754                                         \n",
      "Epoch 086 | Train 23.2963 | Val 23.3802                                         \n",
      "Epoch 087 | Train 23.1834 | Val 23.0893                                         \n",
      "Epoch 088 | Train 22.8014 | Val 22.7127                                         \n",
      "Epoch 089 | Train 22.6079 | Val 21.5070                                         \n",
      "Epoch 090 | Train 22.7552 | Val 21.4728                                         \n",
      "Epoch 091 | Train 21.9053 | Val 21.1094                                         \n",
      "Epoch 092 | Train 22.2423 | Val 20.9150                                         \n",
      "Epoch 093 | Train 22.1056 | Val 21.1706                                         \n",
      "Epoch 094 | Train 21.9750 | Val 21.9288                                         \n",
      "Epoch 095 | Train 21.9330 | Val 21.2304                                         \n",
      "Epoch 096 | Train 21.6667 | Val 20.1658                                         \n",
      "Epoch 097 | Train 21.4955 | Val 20.3423                                         \n",
      "Epoch 098 | Train 21.4777 | Val 20.5011                                         \n",
      "Epoch 099 | Train 20.9202 | Val 21.8940                                         \n",
      "Epoch 100 | Train 20.9424 | Val 20.8301                                         \n",
      "Epoch 101 | Train 21.2088 | Val 20.2930                                         \n",
      "Epoch 102 | Train 20.6302 | Val 19.7178                                         \n",
      "Epoch 103 | Train 21.2261 | Val 20.6951                                         \n",
      "Epoch 104 | Train 20.5111 | Val 19.9431                                         \n",
      "Epoch 105 | Train 20.3872 | Val 19.3652                                         \n",
      "Epoch 106 | Train 20.3604 | Val 19.6852                                         \n",
      "Epoch 107 | Train 20.0322 | Val 18.5764                                         \n",
      "Epoch 108 | Train 20.0182 | Val 20.2231                                         \n",
      "Epoch 109 | Train 19.8231 | Val 18.4841                                         \n",
      "Epoch 110 | Train 20.1351 | Val 19.2410                                         \n",
      "Epoch 111 | Train 19.6416 | Val 19.2063                                         \n",
      "Epoch 112 | Train 19.2704 | Val 18.7104                                         \n",
      "Epoch 113 | Train 19.2069 | Val 18.9474                                         \n",
      "Epoch 114 | Train 19.5255 | Val 19.2690                                         \n",
      "Epoch 115 | Train 19.0789 | Val 17.8229                                         \n",
      "Epoch 116 | Train 19.0723 | Val 18.5958                                         \n",
      "Epoch 117 | Train 18.9688 | Val 18.0005                                         \n",
      "Epoch 118 | Train 19.3259 | Val 19.0713                                         \n",
      "Epoch 119 | Train 19.1965 | Val 17.0500                                         \n",
      "Epoch 120 | Train 18.6109 | Val 18.9050                                         \n",
      "Epoch 121 | Train 18.6215 | Val 17.3969                                         \n",
      "Epoch 122 | Train 18.5991 | Val 18.0548                                         \n",
      "Epoch 123 | Train 18.8247 | Val 17.6837                                         \n",
      "Epoch 124 | Train 18.1770 | Val 17.1591                                         \n",
      "Epoch 125 | Train 18.4197 | Val 17.8897                                         \n",
      "Epoch 126 | Train 18.2884 | Val 16.5543                                         \n",
      "Epoch 127 | Train 18.1180 | Val 17.4217                                         \n",
      "Epoch 128 | Train 18.0588 | Val 17.0656                                         \n",
      "Epoch 129 | Train 17.7371 | Val 17.0807                                         \n",
      "Epoch 130 | Train 17.8210 | Val 16.7786                                         \n",
      "Epoch 131 | Train 17.6401 | Val 17.1422                                         \n",
      "Epoch 132 | Train 17.6117 | Val 17.5657                                         \n",
      "Epoch 133 | Train 17.3819 | Val 16.8538                                         \n",
      "Epoch 134 | Train 17.4024 | Val 17.4327                                         \n",
      "Epoch 135 | Train 17.1996 | Val 16.7071                                         \n",
      "Epoch 136 | Train 17.4187 | Val 16.4706                                         \n",
      "Epoch 137 | Train 17.1637 | Val 15.7933                                         \n",
      "Epoch 138 | Train 17.2768 | Val 16.8289                                         \n",
      "Epoch 139 | Train 17.2552 | Val 16.9447                                         \n",
      "Epoch 140 | Train 17.1974 | Val 16.1829                                         \n",
      "Epoch 141 | Train 16.6863 | Val 16.1925                                         \n",
      "Epoch 142 | Train 17.0030 | Val 15.8874                                         \n",
      "Epoch 143 | Train 16.7586 | Val 16.1972                                         \n",
      "Epoch 144 | Train 16.6723 | Val 16.1440                                         \n",
      "Epoch 145 | Train 16.4873 | Val 15.2103                                         \n",
      "Epoch 146 | Train 16.5600 | Val 15.8910                                         \n",
      "Epoch 147 | Train 16.4411 | Val 15.5310                                         \n",
      "Epoch 148 | Train 16.4296 | Val 15.6137                                         \n",
      "Epoch 149 | Train 16.1521 | Val 16.0988                                         \n",
      "Training: 100%|██████████████████████████| 150/150 [1:20:08<00:00, 32.06s/epoch]\n",
      "Best epoch: 145\n",
      "✅ Best model saved: best_model.pt\n",
      "📈 Saved loss_curve.png\n",
      "✅ Contrastive finished\n",
      "Embeddings: torch.Size([5000, 512])\n",
      "Saved: /root/HGMAE/embeddings.npy\n",
      "⏱️ Total time: 4813 s\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE\n",
    "!python main.py --dataset mydata --task contrastive --use_cfg --epochs 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b87024f-f2b4-4439-8ffe-d573451e17c7",
   "metadata": {},
   "source": [
    "## Final Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f25c41a-c3f3-49af-9242-0f271a901d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5000, 512)\n",
      "Dtype: float32\n",
      "First 5 embeddings:\n",
      " [[0.24876194 0.14389117 0.46494567 ... 0.2660499  0.17222154 0.05553541]\n",
      " [0.17449698 0.13445519 0.5479781  ... 0.26801953 0.34459224 0.29198402]\n",
      " [0.28962123 0.22092982 0.36324188 ... 0.05182059 0.1699028  0.12909499]\n",
      " ...\n",
      " [0.2193987  0.01143015 0.44400483 ... 0.28498003 0.03462566 0.22011498]\n",
      " [0.24123284 0.37747315 0.24810821 ... 0.15827772 0.17780797 0.1730656 ]\n",
      " [0.3867326  0.03622517 0.37573007 ... 0.34329483 0.28516996 0.13198513]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 파일 경로\n",
    "path = \"/root/HGMAE/embeddings.npy\"\n",
    "\n",
    "# 불러오기\n",
    "embeddings = np.load(path)\n",
    "\n",
    "print(\"Shape:\", embeddings.shape)\n",
    "print(\"Dtype:\", embeddings.dtype)\n",
    "\n",
    "# 앞 5개 행 출력\n",
    "print(\"First 5 embeddings:\\n\", embeddings[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f2eb1f-ff54-45e8-85e7-a20f80c3a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행 수: 5000\n",
      "cs_data 행 수: 5000\n",
      "0    https://openalex.org/W3010906965\n",
      "1    https://openalex.org/W4213446860\n",
      "2    https://openalex.org/W2987460522\n",
      "3    https://openalex.org/W3133928066\n",
      "4    https://openalex.org/W4382464460\n",
      "Name: paper_id, dtype: object\n",
      "첫 번째 임베딩 벡터: [ 0.24876194  0.14389117  0.46494567 -0.01029712  0.07939439  0.08515264\n",
      "  0.5616668   0.09866195 -0.23705757  0.18434714]\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"/root/HGMAE/embeddings.npy\")\n",
    "meta_df = pd.read_csv(\"/root/cs_data.csv\")\n",
    "\n",
    "print(\"임베딩 행 수:\", embeddings.shape[0])\n",
    "print(\"cs_data 행 수:\", len(meta_df))\n",
    "\n",
    "# paper_id 앞 5개 출력\n",
    "print(meta_df[\"paper_id\"].head())\n",
    "\n",
    "# 임베딩 앞 1개 벡터 길이 확인\n",
    "print(\"첫 번째 임베딩 벡터:\", embeddings[0][:10])  # 앞 10차원만 보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b55cd74-e133-40f8-bc46-f68f98723b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /root/HGMAE/hgmae_embeddings_with_paperid.csv shape: (5000, 513)\n"
     ]
    }
   ],
   "source": [
    "# paper_id 컬럼 맨앞에 붙여서 다시 저장 \n",
    "\n",
    "embeddings = np.load(\"/root/HGMAE/embeddings.npy\")\n",
    "meta_df = pd.read_csv(\"/root/cs_data.csv\")\n",
    "\n",
    "df = pd.DataFrame(embeddings)\n",
    "df.insert(0, \"paper_id\", meta_df[\"paper_id\"].values)\n",
    "\n",
    "OUT_PATH = \"/root/HGMAE/hgmae_embeddings_with_paperid.csv\"\n",
    "df.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH, \"shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd4871-28da-47d4-b8f4-bba37c251dfd",
   "metadata": {},
   "source": [
    "## Pos/Neg pair split 잘 됐는지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "921acb16-2858-46d0-9722-c29f04318e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n",
      "Top-level keys: dict_keys(['pos', 'neg'])\n",
      "Subkeys (pos): dict_keys(['train', 'val'])\n",
      "Subkeys (neg): dict_keys(['train', 'val'])\n",
      "\n",
      "=== POS_TRAIN[PAPER] ===\n",
      "총 개수: 6823\n",
      "중복 제거 후 개수: 6823 (중복 0)\n",
      "유효하지 않은 노드 index 개수: 0\n",
      "\n",
      "=== NEG_TRAIN[PAPER] ===\n",
      "총 개수: 6822\n",
      "중복 제거 후 개수: 6822 (중복 0)\n",
      "유효하지 않은 노드 index 개수: 0\n",
      "\n",
      "Pos-Neg 교집합 개수: 0\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# 파일 로드\n",
    "with open(\"pairs_debug.pkl\", \"rb\") as f:\n",
    "    pairs = pickle.load(f)\n",
    "\n",
    "print(\"Top-level keys:\", pairs.keys())\n",
    "print(\"Subkeys (pos):\", pairs[\"pos\"].keys())\n",
    "print(\"Subkeys (neg):\", pairs[\"neg\"].keys())\n",
    "\n",
    "def check_edges(edges, name, num_nodes=None):\n",
    "    print(f\"\\n=== {name.upper()} ===\")\n",
    "    if edges is None or len(edges) == 0:\n",
    "        print(\"⚠️ 없음\")\n",
    "        return None\n",
    "    \n",
    "    if isinstance(edges, torch.Tensor):\n",
    "        e = edges.clone().cpu()\n",
    "        if e.ndim == 2 and e.shape[0] == 2:\n",
    "            e = e.t()\n",
    "    else:\n",
    "        e = torch.as_tensor(edges, dtype=torch.long)\n",
    "        if e.ndim == 2 and e.shape[0] == 2:\n",
    "            e = e.t()\n",
    "    \n",
    "    print(f\"총 개수: {e.shape[0]}\")\n",
    "    \n",
    "    uniq = torch.unique(e, dim=0)\n",
    "    print(f\"중복 제거 후 개수: {uniq.shape[0]} (중복 {e.shape[0] - uniq.shape[0]})\")\n",
    "    \n",
    "    if num_nodes:\n",
    "        invalid = ((e < 0) | (e >= num_nodes)).any(dim=1).sum().item()\n",
    "        print(f\"유효하지 않은 노드 index 개수: {invalid}\")\n",
    "    \n",
    "    return e\n",
    "\n",
    "# 예시: paper 타입만 확인\n",
    "pos_paper = pairs[\"pos\"][\"train\"].get(\"paper\")\n",
    "neg_paper = pairs[\"neg\"][\"train\"].get(\"paper\")\n",
    "\n",
    "pos_e = check_edges(pos_paper, \"pos_train[paper]\", num_nodes=5000)\n",
    "neg_e = check_edges(neg_paper, \"neg_train[paper]\", num_nodes=5000)\n",
    "\n",
    "# pos-neg 교집합\n",
    "if pos_e is not None and neg_e is not None:\n",
    "    inter = set(map(tuple, pos_e.tolist())) & set(map(tuple, neg_e.tolist()))\n",
    "    print(f\"\\nPos-Neg 교집합 개수: {len(inter)}\")\n",
    "    if len(inter) > 0:\n",
    "        print(\"예시 교집합:\", list(inter)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a4c7a24-07d1-4caf-88ca-d8a88b4cc43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HGMAE\n",
      "Keys in mydata.pkl: dict_keys(['feats', 'mps', 'nei_index', 'pos'])\n",
      "Type of pos: <class 'dict'>\n",
      "ap: shape=torch.Size([2, 40758]) type=<class 'torch.Tensor'>\n",
      "pc: shape=torch.Size([2, 82238]) type=<class 'torch.Tensor'>\n",
      "pp: shape=torch.Size([2, 8186]) type=<class 'torch.Tensor'>\n",
      "aa: shape=torch.Size([2, 984700]) type=<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "%cd /root/HGMAE\n",
    "import torch\n",
    "\n",
    "data = torch.load(\"data/mydata.pkl\", map_location=\"cpu\")  # GPU → CPU 로드\n",
    "print(\"Keys in mydata.pkl:\", data.keys())\n",
    "\n",
    "if \"pos\" in data:\n",
    "    pos = data[\"pos\"]\n",
    "    print(\"Type of pos:\", type(pos))\n",
    "    if isinstance(pos, dict):\n",
    "        for k, v in pos.items():\n",
    "            print(f\"{k}: shape={getattr(v, 'shape', None)} type={type(v)}\")\n",
    "    else:\n",
    "        print(\"pos content:\", pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02ce15-57fa-425c-8dcb-9fcf9d319278",
   "metadata": {},
   "source": [
    "## Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070261a-e463-4e7f-80bc-bfef50af5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/HGMAE\n",
    "!python main.py --dataset mydata --task contrastive --use_cfg --epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9ac47-4f42-42bc-8fd6-91f4380104f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/HGMAE\n",
    "!python main.py --dataset mydata --task contrastive --use_cfg --epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c26285-1751-4315-a7c6-c8599ba3e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/HGMAE\n",
    "!python main.py --dataset mydata --task contrastive --use_cfg --epochs 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e500116-5f0b-432f-b6bd-dba5ba411214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf2ec3-9f1a-4d8d-b057-0f14ac94272d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
